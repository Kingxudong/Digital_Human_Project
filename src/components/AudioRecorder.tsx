import React, { useState, useRef, useCallback, useEffect } from 'react';
import { Button, message } from 'antd';
import { AudioOutlined, StopOutlined, SoundOutlined } from '@ant-design/icons';

interface AudioRecorderProps {
  onSTTResult: (text: string, isFinal: boolean, confidence: number) => void;
  onError: (error: string) => void;
  onStatusChange: (status: string) => void;
  websocketUrl: string;
  sessionId: string;
}

const AudioRecorder: React.FC<AudioRecorderProps> = ({
  onSTTResult,
  onError,
  onStatusChange,
  websocketUrl,
  sessionId
}) => {
  const [isRecording, setIsRecording] = useState(false);
  const [isConnected, setIsConnected] = useState(false);
  const [isInRecordMode, setIsInRecordMode] = useState(false); // æ˜¯å¦è¿›å…¥å½•éŸ³æ¨¡å¼
  const [isLongPressing, setIsLongPressing] = useState(false); // æ˜¯å¦æ­£åœ¨é•¿æŒ‰
  
  const websocketRef = useRef<WebSocket | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const processorRef = useRef<ScriptProcessorNode | null>(null);
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const isRecordingRef = useRef<boolean>(false); // ç”¨äºéŸ³é¢‘å¤„ç†å›è°ƒä¸­è®¿é—®æœ€æ–°çš„å½•éŸ³çŠ¶æ€
  const longPressTimerRef = useRef<NodeJS.Timeout | null>(null); // é•¿æŒ‰å®šæ—¶å™¨
  const isMobileRef = useRef<boolean>(false); // æ˜¯å¦ä¸ºç§»åŠ¨ç«¯

  // è¿æ¥WebSocket
  const connectWebSocket = useCallback(async () => {
    try {
      console.log('ğŸ”Œ å¼€å§‹è¿æ¥WebSocket:', websocketUrl);
      onStatusChange('æ­£åœ¨è¿æ¥WebSocket...');
      
      const ws = new WebSocket(websocketUrl);
      websocketRef.current = ws;

      ws.onopen = () => {
        console.log('âœ… WebSocketè¿æ¥æˆåŠŸ');
        setIsConnected(true);
        onStatusChange('WebSocketè¿æ¥æˆåŠŸ');
        
        // å‘é€helloæ¶ˆæ¯ - å‰ç«¯å½•éŸ³åè®®
        const helloMessage = {
          type: 'hello',
          session_id: sessionId,
          capabilities: {
            audio: true,
            stt: true,
            pcm_format: true
          },
          audio_params: {
            format: 'pcm',
            sample_rate: 16000,
            channels: 1,
            bits_per_sample: 16
          }
        };
        console.log('ğŸ“¤ å‘é€helloæ¶ˆæ¯:', helloMessage);
        ws.send(JSON.stringify(helloMessage));
      };

      ws.onmessage = (event) => {
        console.log('ğŸ“¨ æ”¶åˆ°WebSocketæ¶ˆæ¯:', event.data);
        try {
          const data = JSON.parse(event.data);
          console.log('ğŸ“¨ è§£æåçš„æ¶ˆæ¯æ•°æ®:', data);
          
          if (data.type === 'hello_ack') {
            console.log('âœ… æ”¶åˆ°helloç¡®è®¤æ¶ˆæ¯');
            onStatusChange('éŸ³é¢‘æœåŠ¡å°±ç»ª');
          } else if (data.type === 'recording_start_ack') {
            console.log('âœ… æ”¶åˆ°å½•éŸ³å¼€å§‹ç¡®è®¤æ¶ˆæ¯');
            onStatusChange('å½•éŸ³å·²å¼€å§‹');
          } else if (data.type === 'recording_end_ack') {
            console.log('âœ… æ”¶åˆ°å½•éŸ³ç»“æŸç¡®è®¤æ¶ˆæ¯');
            onStatusChange('å½•éŸ³å·²ç»“æŸ');
          } else if (data.type === 'stt_result') {
            console.log('ğŸ¯ æ”¶åˆ°STTç»“æœ:', data);
            console.log('ğŸ¯ STTç»“æœæ•°æ®ç»“æ„:', JSON.stringify(data, null, 2));
            const { text, is_final, confidence } = data.data;
            console.log('ğŸ¯ æå–çš„STTæ•°æ®:', { text, is_final, confidence });
            console.log('ğŸ¯ å‡†å¤‡è°ƒç”¨onSTTResultå›è°ƒå‡½æ•°');
            onSTTResult(text, is_final || false, confidence || 0.85);
            console.log('ğŸ¯ onSTTResultå›è°ƒå‡½æ•°è°ƒç”¨å®Œæˆ');
          } else if (data.type === 'error') {
            console.error('âŒ æ”¶åˆ°é”™è¯¯æ¶ˆæ¯:', data);
            onError(data.data?.message || data.message || 'æœªçŸ¥é”™è¯¯');
          } else {
            console.log('ğŸ“¨ æ”¶åˆ°æœªçŸ¥ç±»å‹æ¶ˆæ¯:', data.type);
          }
        } catch (error) {
          console.error('âŒ è§£æWebSocketæ¶ˆæ¯å¤±è´¥:', error);
          const errorMessage = error instanceof Error ? error.message : String(error);
          console.error('è§£æé”™è¯¯è¯¦æƒ…:', errorMessage);
        }
      };

      ws.onerror = (error) => {
        console.error('WebSocketé”™è¯¯:', error);
        onError('WebSocketè¿æ¥é”™è¯¯');
        setIsConnected(false);
      };

      ws.onclose = () => {
        console.log('WebSocketè¿æ¥å…³é—­');
        setIsConnected(false);
        onStatusChange('WebSocketè¿æ¥å·²æ–­å¼€');
      };

    } catch (error) {
      console.error('è¿æ¥WebSocketå¤±è´¥:', error);
      const errorMessage = error instanceof Error ? error.message : String(error);
      onError('è¿æ¥WebSocketå¤±è´¥: ' + errorMessage);
    }
  }, [websocketUrl, sessionId, onSTTResult, onError, onStatusChange]);

  // åˆå§‹åŒ–éŸ³é¢‘
  const initializeAudio = useCallback(async () => {
    try {
      console.log('ğŸµ å¼€å§‹åˆå§‹åŒ–éŸ³é¢‘...');
      onStatusChange('æ­£åœ¨åˆå§‹åŒ–éŸ³é¢‘...');
      
      // è·å–éŸ³é¢‘æƒé™
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });
      
      console.log('âœ… è·å–éŸ³é¢‘æƒé™æˆåŠŸ');
      mediaStreamRef.current = stream;
      
      // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡
      const audioContext = new AudioContext({
        sampleRate: 16000
      });
      audioContextRef.current = audioContext;
      console.log('âœ… åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡æˆåŠŸ');
      
      // åˆ›å»ºéŸ³é¢‘æº
      const source = audioContext.createMediaStreamSource(stream);
      sourceRef.current = source;
      console.log('âœ… åˆ›å»ºéŸ³é¢‘æºæˆåŠŸ');
      
      // åˆ›å»ºéŸ³é¢‘å¤„ç†å™¨
      const processor = audioContext.createScriptProcessor(4096, 1, 1);
      processorRef.current = processor;
      console.log('âœ… åˆ›å»ºéŸ³é¢‘å¤„ç†å™¨æˆåŠŸ');
      
      // éŸ³é¢‘å¤„ç†å›è°ƒ - ä½¿ç”¨refæ¥è®¿é—®æœ€æ–°çš„çŠ¶æ€
      processor.onaudioprocess = (event) => {
        // ä½¿ç”¨refæ¥è·å–æœ€æ–°çš„isRecordingçŠ¶æ€ï¼Œé¿å…é—­åŒ…é—®é¢˜
        const currentIsRecording = isRecordingRef.current;
        const currentWebSocket = websocketRef.current;
        
        console.log('ğŸ¤ éŸ³é¢‘å¤„ç†å›è°ƒè¢«è§¦å‘', {
          isRecording: currentIsRecording,
          websocketReadyState: currentWebSocket?.readyState,
          inputBufferLength: event.inputBuffer.length
        });
        
        // æ£€æŸ¥WebSocketè¿æ¥çŠ¶æ€å’Œå½•éŸ³çŠ¶æ€
        if (currentIsRecording && currentWebSocket?.readyState === WebSocket.OPEN) {
          const inputBuffer = event.inputBuffer;
          const pcmData = inputBuffer.getChannelData(0);
          
          // è½¬æ¢ä¸º16ä½PCM
          const pcm16 = new Int16Array(pcmData.length);
          for (let i = 0; i < pcmData.length; i++) {
            pcm16[i] = Math.max(-32768, Math.min(32767, pcmData[i] * 32768));
          }
          
          // å‘é€éŸ³é¢‘æ•°æ® - ç›´æ¥å‘é€æ•´ä¸ªéŸ³é¢‘å—
          try {
            currentWebSocket.send(pcm16.buffer);
            console.log('ğŸµ å‘é€éŸ³é¢‘æ•°æ®å—ï¼Œå¤§å°:', pcm16.buffer.byteLength, 'å­—èŠ‚');
          } catch (error) {
            console.error('âŒ å‘é€éŸ³é¢‘æ•°æ®å¤±è´¥:', error);
          }
        } else {
          console.log('ğŸ”‡ è·³è¿‡éŸ³é¢‘å‘é€:', {
            isRecording: currentIsRecording,
            websocketReadyState: currentWebSocket?.readyState,
            websocketOpen: currentWebSocket?.readyState === WebSocket.OPEN
          });
        }
      };
      
      // è¿æ¥éŸ³é¢‘èŠ‚ç‚¹
      source.connect(processor);
      processor.connect(audioContext.destination);
      console.log('âœ… éŸ³é¢‘èŠ‚ç‚¹è¿æ¥æˆåŠŸ');
      
      onStatusChange('éŸ³é¢‘åˆå§‹åŒ–å®Œæˆ');
      
    } catch (error) {
      console.error('âŒ åˆå§‹åŒ–éŸ³é¢‘å¤±è´¥:', error);
      const errorMessage = error instanceof Error ? error.message : String(error);
      onError('åˆå§‹åŒ–éŸ³é¢‘å¤±è´¥: ' + errorMessage);
    }
  }, [isRecording, onStatusChange, onError]);

  // åŒæ­¥å½•éŸ³çŠ¶æ€åˆ°ref
  useEffect(() => {
    isRecordingRef.current = isRecording;
  }, [isRecording]);

  // å¼€å§‹å½•éŸ³
  const startRecording = useCallback(async () => {
    console.log('ğŸ¤ å¼€å§‹å½•éŸ³æŒ‰é’®è¢«ç‚¹å‡»');
    console.log('å½“å‰çŠ¶æ€:', {
      isConnected,
      websocketReadyState: websocketRef.current?.readyState,
      audioContextExists: !!audioContextRef.current,
      sessionId
    });
    
    try {
      // å¦‚æœWebSocketæœªè¿æ¥ï¼Œå°è¯•é‡æ–°è¿æ¥
      if (!isConnected || websocketRef.current?.readyState !== WebSocket.OPEN) {
        console.log('ğŸ”Œ WebSocketæœªè¿æ¥ï¼Œå°è¯•é‡æ–°è¿æ¥...');
        await connectWebSocket();
      }
      
      // å‘é€å½•éŸ³å¼€å§‹æ¶ˆæ¯
      if (websocketRef.current?.readyState === WebSocket.OPEN) {
        const startMessage = {
          type: 'recording_start',
          session_id: sessionId
        };
        console.log('ğŸ“¤ å‘é€å½•éŸ³å¼€å§‹æ¶ˆæ¯:', startMessage);
        websocketRef.current.send(JSON.stringify(startMessage));
      } else {
        console.error('âŒ WebSocketæœªè¿æ¥ï¼Œæ— æ³•å‘é€å½•éŸ³å¼€å§‹æ¶ˆæ¯');
        onError('WebSocketè¿æ¥å¤±è´¥ï¼Œæ— æ³•å¼€å§‹å½•éŸ³');
        return;
      }
      
      // åˆå§‹åŒ–éŸ³é¢‘ï¼ˆå¦‚æœè¿˜æ²¡æœ‰åˆå§‹åŒ–ï¼‰
      if (!audioContextRef.current) {
        console.log('ğŸµ éŸ³é¢‘ä¸Šä¸‹æ–‡ä¸å­˜åœ¨ï¼Œåˆå§‹åŒ–éŸ³é¢‘...');
        await initializeAudio();
      }
      
      // æœ€åè®¾ç½®å½•éŸ³çŠ¶æ€ä¸ºtrueï¼Œè¿™æ ·éŸ³é¢‘å¤„ç†å™¨å°±ä¼šå¼€å§‹å‘é€æ•°æ®
      console.log('âœ… è®¾ç½®å½•éŸ³çŠ¶æ€ä¸ºtrue');
      setIsRecording(true);
      isRecordingRef.current = true; // åŒæ—¶æ›´æ–°ref
      onStatusChange('æ­£åœ¨å½•éŸ³...');
      
    } catch (error) {
      console.error('âŒ å¼€å§‹å½•éŸ³å¤±è´¥:', error);
      const errorMessage = error instanceof Error ? error.message : String(error);
      onError('å¼€å§‹å½•éŸ³å¤±è´¥: ' + errorMessage);
      // å¦‚æœå‡ºé”™ï¼Œé‡ç½®å½•éŸ³çŠ¶æ€
      setIsRecording(false);
    }
  }, [isConnected, connectWebSocket, initializeAudio, sessionId, onStatusChange, onError]);

  // åœæ­¢å½•éŸ³
  const stopRecording = useCallback(async () => {
    console.log('â¹ï¸ åœæ­¢å½•éŸ³æŒ‰é’®è¢«ç‚¹å‡»');
    console.log('å½“å‰çŠ¶æ€:', {
      isRecording,
      websocketReadyState: websocketRef.current?.readyState,
      sessionId
    });
    
    try {
      console.log('âœ… è®¾ç½®å½•éŸ³çŠ¶æ€ä¸ºfalse');
      setIsRecording(false);
      isRecordingRef.current = false; // åŒæ—¶æ›´æ–°ref
      onStatusChange('å½•éŸ³å·²åœæ­¢');
      
      // ç§»åŠ¨ç«¯å½•éŸ³å®Œæˆåé€€å‡ºå½•éŸ³æ¨¡å¼
      if (isMobileRef.current) {
        setIsInRecordMode(false);
        setIsLongPressing(false);
      }
      
      // å‘é€å½•éŸ³ç»“æŸä¿¡å·
      if (websocketRef.current?.readyState === WebSocket.OPEN) {
        const endMessage = {
          type: 'recording_end',
          session_id: sessionId
        };
        console.log('ğŸ“¤ å‘é€å½•éŸ³ç»“æŸæ¶ˆæ¯:', endMessage);
        websocketRef.current.send(JSON.stringify(endMessage));
      } else {
        console.warn('âš ï¸ WebSocketæœªè¿æ¥ï¼Œæ— æ³•å‘é€å½•éŸ³ç»“æŸæ¶ˆæ¯');
      }
      
    } catch (error) {
      console.error('âŒ åœæ­¢å½•éŸ³å¤±è´¥:', error);
      const errorMessage = error instanceof Error ? error.message : String(error);
      onError('åœæ­¢å½•éŸ³å¤±è´¥: ' + errorMessage);
    }
  }, [sessionId, onStatusChange, onError, isRecording]);

  // ç§»åŠ¨ç«¯é•¿æŒ‰å¼€å§‹å½•éŸ³
  const handleTouchStart = useCallback(async (e: React.TouchEvent) => {
    if (!isMobileRef.current || !isInRecordMode) return;
    
    e.preventDefault();
    console.log('ğŸ“± ç§»åŠ¨ç«¯è§¦æ‘¸å¼€å§‹');
    
    // è®¾ç½®é•¿æŒ‰å®šæ—¶å™¨
    longPressTimerRef.current = setTimeout(async () => {
      console.log('ğŸ“± é•¿æŒ‰è§¦å‘ï¼Œå¼€å§‹å½•éŸ³');
      setIsLongPressing(true);
      await startRecording();
    }, 500); // 500msé•¿æŒ‰è§¦å‘
  }, [isInRecordMode, startRecording]);

  // ç§»åŠ¨ç«¯è§¦æ‘¸ç»“æŸ
  const handleTouchEnd = useCallback(async (e: React.TouchEvent) => {
    if (!isMobileRef.current || !isInRecordMode) return;
    
    e.preventDefault();
    console.log('ğŸ“± ç§»åŠ¨ç«¯è§¦æ‘¸ç»“æŸ');
    
    // æ¸…é™¤é•¿æŒ‰å®šæ—¶å™¨
    if (longPressTimerRef.current) {
      clearTimeout(longPressTimerRef.current);
      longPressTimerRef.current = null;
    }
    
    // å¦‚æœæ­£åœ¨å½•éŸ³ï¼Œåœæ­¢å½•éŸ³
    if (isLongPressing) {
      console.log('ğŸ“± åœæ­¢å½•éŸ³');
      setIsLongPressing(false);
      await stopRecording();
    }
  }, [isInRecordMode, isLongPressing, stopRecording]);

  // ç§»åŠ¨ç«¯è§¦æ‘¸å–æ¶ˆ
  const handleTouchCancel = useCallback((e: React.TouchEvent) => {
    if (!isMobileRef.current || !isInRecordMode) return;
    
    e.preventDefault();
    console.log('ğŸ“± ç§»åŠ¨ç«¯è§¦æ‘¸å–æ¶ˆ');
    
    // æ¸…é™¤é•¿æŒ‰å®šæ—¶å™¨
    if (longPressTimerRef.current) {
      clearTimeout(longPressTimerRef.current);
      longPressTimerRef.current = null;
    }
    
    // å¦‚æœæ­£åœ¨å½•éŸ³ï¼Œåœæ­¢å½•éŸ³
    if (isLongPressing) {
      setIsLongPressing(false);
      stopRecording();
    }
  }, [isInRecordMode, isLongPressing, stopRecording]);

  // æ¡Œé¢ç«¯ç‚¹å‡»å¤„ç†
  const handleClick = useCallback(async (e: React.MouseEvent) => {
    if (isMobileRef.current) return; // ç§»åŠ¨ç«¯ä¸å¤„ç†ç‚¹å‡»
    
    console.log('ğŸ–±ï¸ æ¡Œé¢ç«¯ç‚¹å‡»');
    if (isRecording) {
      await stopRecording();
    } else {
      await startRecording();
    }
  }, [isRecording, startRecording, stopRecording]);

  // ç§»åŠ¨ç«¯ç‚¹å‡»è¿›å…¥å½•éŸ³æ¨¡å¼
  const handleMobileClick = useCallback((e: React.MouseEvent) => {
    if (!isMobileRef.current) return;
    
    e.preventDefault();
    console.log('ğŸ“± ç§»åŠ¨ç«¯ç‚¹å‡»ï¼Œè¿›å…¥å½•éŸ³æ¨¡å¼');
    setIsInRecordMode(true);
  }, []);

  // æ£€æµ‹æ˜¯å¦ä¸ºç§»åŠ¨ç«¯
  useEffect(() => {
    isMobileRef.current = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
  }, []);

  // ç»„ä»¶åŠ è½½æ—¶è‡ªåŠ¨è¿æ¥WebSocket
  useEffect(() => {
    console.log('ğŸš€ AudioRecorderç»„ä»¶åˆå§‹åŒ–', {
      websocketUrl,
      sessionId,
      timestamp: new Date().toISOString()
    });
    
    // è‡ªåŠ¨è¿æ¥WebSocket
    connectWebSocket();
    
    // æ¸…ç†èµ„æº
    return () => {
      console.log('ğŸ§¹ AudioRecorderç»„ä»¶æ¸…ç†èµ„æº');
      if (processorRef.current) {
        processorRef.current.disconnect();
      }
      if (sourceRef.current) {
        sourceRef.current.disconnect();
      }
      if (mediaStreamRef.current) {
        mediaStreamRef.current.getTracks().forEach(track => track.stop());
      }
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close();
      }
      if (websocketRef.current) {
        websocketRef.current.close();
      }
      // æ¸…ç†é•¿æŒ‰å®šæ—¶å™¨
      if (longPressTimerRef.current) {
        clearTimeout(longPressTimerRef.current);
      }
    };
  }, []); // ç§»é™¤connectWebSocketä¾èµ–ï¼Œé¿å…é‡å¤è¿æ¥

  // æ ¹æ®çŠ¶æ€ç¡®å®šæŒ‰é’®æ ·å¼å’Œå†…å®¹
  const getButtonContent = () => {
    if (isMobileRef.current) {
      if (isInRecordMode) {
        if (isLongPressing || isRecording) {
          // æ­£åœ¨å½•éŸ³çŠ¶æ€
          return {
            text: 'æ¾å¼€ç»“æŸ',
            icon: <StopOutlined />,
            background: '#ff4d4f',
            color: 'white',
            border: 'none'
          };
        } else {
          // å½•éŸ³æ¨¡å¼ï¼Œç­‰å¾…é•¿æŒ‰
          return {
            text: 'æŒ‰ä½è¯´è¯',
            icon: <SoundOutlined />,
            background: '#1890ff',
            color: 'white',
            border: 'none'
          };
        }
      } else {
        // åˆå§‹çŠ¶æ€
        return {
          text: '',
          icon: <SoundOutlined />,
          background: 'rgba(255,255,255,0.8)',
          color: '#6b7280',
          border: '1px solid #d1d5db'
        };
      }
    } else {
      // æ¡Œé¢ç«¯
      if (isRecording) {
        return {
          text: '',
          icon: <StopOutlined />,
          background: '#ff4d4f',
          color: 'white',
          border: 'none'
        };
      } else {
        return {
          text: '',
          icon: <SoundOutlined />,
          background: 'rgba(255,255,255,0.8)',
          color: '#6b7280',
          border: '1px solid #d1d5db'
        };
      }
    }
  };

  const buttonContent = getButtonContent();

  return (
    <Button
      type={isRecording || isLongPressing ? "primary" : "default"}
      icon={buttonContent.icon}
      onClick={isMobileRef.current ? handleMobileClick : handleClick}
      onTouchStart={handleTouchStart}
      onTouchEnd={handleTouchEnd}
      onTouchCancel={handleTouchCancel}
      size="middle"
      style={{
        borderRadius: isMobileRef.current && isInRecordMode ? '20px' : '50%',
        background: buttonContent.background,
        border: buttonContent.border,
        color: buttonContent.color,
        fontWeight: '600',
                 width: isMobileRef.current && isInRecordMode ? '100px' : '24px',
         height: isMobileRef.current && isInRecordMode ? '32px' : '24px',
        display: 'flex',
        alignItems: 'center',
        justifyContent: 'center',
        boxShadow: isRecording || isLongPressing ? '0 2px 8px rgba(255, 77, 79, 0.3)' : '0 1px 3px rgba(0, 0, 0, 0.1)',
        transition: 'all 0.2s ease',
        fontSize: isMobileRef.current && isInRecordMode ? '14px' : '12px',
        whiteSpace: 'nowrap',
        overflow: 'hidden',
        textOverflow: 'ellipsis'
      }}
    >
      {buttonContent.text}
    </Button>
  );
};

export default AudioRecorder;
